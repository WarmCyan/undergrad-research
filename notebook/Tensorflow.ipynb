{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tensorflow (LSTM's)\n",
    "\n",
    "Some references:\n",
    "* [https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537](https://towardsdatascience.com/lstm-by-example-using-tensorflow-feb0c1968537)\n",
    "* [https://www.tensorflow.org/tutorials/recurrent](https://www.tensorflow.org/tutorials/recurrent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to build a dataset (returns a unique id associated with each word)\n",
    "This particular example mapping is built by frequency of each word. (So the most common word is id 0, next most common is 1, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build dataset from one of Aesop's short stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = \"long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .\"\n",
    "data = data.split(' ')\n",
    "\n",
    "dictionary, reverse_dictionary = build_dataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up network variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(dictionary)\n",
    "\n",
    "n_input = 3 # TODO: grab 3 words at a time as input?\n",
    "n_hidden = 512 # number of hidden units in the RNN cell\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "biases = tf.Variable(tf.random_normal([vocab_size]))\n",
    "\n",
    "x = tf.Variable(tf.random_normal([n_input]))\n",
    "\n",
    "currentState = tf.zeros([batch_size, lstm.state_size])\n",
    "hiddenState = tf.zeros([batch_size, lstm.state_size])\n",
    "#hiddenState = tf.zeros([batch_size, lstm.state_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RNN graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape to [1, n_input]\n",
    "x = tf.reshape(x, [-1, n_input]) # TODO: why -1? What does that do?\n",
    "\n",
    "# Generate an n_input-element sequence of inputs\n",
    "# (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "x = tf.split(x,n_input,1)\n",
    "\n",
    "# 1-layer LSTM with n-hidden units\n",
    "lstm = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "# generate prediction\n",
    "outputs, states = rnn.static_rnn(lstm, x, dtype=tf.float32)\n",
    "\n",
    " # there are n_input outputs but we only want the last output\n",
    "rnn_out = tf.matmul(outputs[-1], weights) + biases\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
